{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Classification Dataset\n",
    "\n",
    "This data is from the Behavioral Risk Factor Surveillance System (BRFSS) which is a health-related telephone survey that is collected annually by the CDC. The goal of this project is to train classification machine learning models to compare model performance based on model type and dataset characteristics. Being able to help classify patients for higher risk of diabetes could help prevent health outcomes linked to undiagnosed diabetes/prediabetes. Early disease detection could help both patients and physicians with better diagnosis.  \n",
    "\n",
    "The original data is the linked Dataset from the University of California Irvine ML Repository. The linked data opens a kaggle dataset which was obtained from the original CDC posted kaggle dataset. \n",
    "\n",
    "The CSV file of interest to compare model performance:\n",
    "- diabetes _ 012 _ health _ indicators _ BRFSS2015.csv is a dataset of 253,680 survey responses to the CDC's BRFSS2015. The target variable Diabetes_012 has 3 classes. 0 is for no diabetes or only during pregnancy, 1 is for prediabetes, and 2 is for diabetes. There is class imbalance in this dataset. This dataset has 21 feature variables.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports, package imports and dataframe setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries for the project\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a DataFrame in pandas\n",
    "data = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset:(253680, 22)\n",
      "Total Memory Usage: 42.58 MB\n",
      "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
      "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(f\"Shape of dataset:{data.shape}\")\n",
    "\n",
    "# MegaByte size of the file\n",
    "total_memory_usage_bytes = data.memory_usage(deep=True).sum()\n",
    "megabytes = total_memory_usage_bytes / (1024**2)\n",
    "print(f'Total Memory Usage: {megabytes:.2f} MB')\n",
    "\n",
    "# All column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012            float64\n",
      "HighBP                  float64\n",
      "HighChol                float64\n",
      "CholCheck               float64\n",
      "BMI                     float64\n",
      "Smoker                  float64\n",
      "Stroke                  float64\n",
      "HeartDiseaseorAttack    float64\n",
      "PhysActivity            float64\n",
      "Fruits                  float64\n",
      "Veggies                 float64\n",
      "HvyAlcoholConsump       float64\n",
      "AnyHealthcare           float64\n",
      "NoDocbcCost             float64\n",
      "GenHlth                 float64\n",
      "MentHlth                float64\n",
      "PhysHlth                float64\n",
      "DiffWalk                float64\n",
      "Sex                     float64\n",
      "Age                     float64\n",
      "Education               float64\n",
      "Income                  float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types for all columns \n",
    "print(data.dtypes)\n",
    "\n",
    "# Print out the first five rows \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012              int64\n",
      "HighBP                    int64\n",
      "HighChol                  int64\n",
      "CholCheck                 int64\n",
      "BMI                     float64\n",
      "Smoker                    int64\n",
      "Stroke                    int64\n",
      "HeartDiseaseorAttack      int64\n",
      "PhysActivity              int64\n",
      "Fruits                    int64\n",
      "Veggies                   int64\n",
      "HvyAlcoholConsump         int64\n",
      "AnyHealthcare             int64\n",
      "NoDocbcCost               int64\n",
      "GenHlth                 float64\n",
      "MentHlth                float64\n",
      "PhysHlth                float64\n",
      "DiffWalk                  int64\n",
      "Sex                       int64\n",
      "Age                     float64\n",
      "Education               float64\n",
      "Income                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the binary columns from float type to int to help with memory/speed when training the data\n",
    "non_binary_columns = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "\n",
    "# Loop through all columns in the dataframe\n",
    "for column in data.columns:\n",
    "    # If the column is not in the list of non-binary columns, convert it to int\n",
    "    if column not in non_binary_columns:\n",
    "        data[column] = data[column].astype(int)\n",
    "\n",
    "\n",
    "# Print out all dtypes after conversion to int\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale our non-binary data to help with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinMaxScaler for scaling data \n",
    "scaler = MinMaxScaler()\n",
    "data[non_binary_columns] = scaler.fit_transform(data[non_binary_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Diabetes Column as Binary value\n",
    "The original data has it as 0 for no diabetes or only during pregnancy, 1 is for prediabetes, and 2 is for diabetes. We will encode the data as either 0 for no diabetes or only during pregnancy, and 1 for prediabetes/diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset to Encode the diabetes column as binary for 0 = no diabetes, and 1 == pre-diabetes or diabetes\n",
    "data['Diabetes_binary'] = (data['Diabetes_012'] > 0).astype(int)\n",
    "\n",
    "# Drop the orginal 'Diabetes_012' column to avoid multicollinearity\n",
    "data = data.drop('Diabetes_012', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighBP                  0\n",
      "HighChol                0\n",
      "CholCheck               0\n",
      "BMI                     0\n",
      "Smoker                  0\n",
      "Stroke                  0\n",
      "HeartDiseaseorAttack    0\n",
      "PhysActivity            0\n",
      "Fruits                  0\n",
      "Veggies                 0\n",
      "HvyAlcoholConsump       0\n",
      "AnyHealthcare           0\n",
      "NoDocbcCost             0\n",
      "GenHlth                 0\n",
      "MentHlth                0\n",
      "PhysHlth                0\n",
      "DiffWalk                0\n",
      "Sex                     0\n",
      "Age                     0\n",
      "Education               0\n",
      "Income                  0\n",
      "Diabetes_binary         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HighBP                    int64\n",
       "HighChol                  int64\n",
       "CholCheck                 int64\n",
       "BMI                     float64\n",
       "Smoker                    int64\n",
       "Stroke                    int64\n",
       "HeartDiseaseorAttack      int64\n",
       "PhysActivity              int64\n",
       "Fruits                    int64\n",
       "Veggies                   int64\n",
       "HvyAlcoholConsump         int64\n",
       "AnyHealthcare             int64\n",
       "NoDocbcCost               int64\n",
       "GenHlth                 float64\n",
       "MentHlth                float64\n",
       "PhysHlth                float64\n",
       "DiffWalk                  int64\n",
       "Sex                       int64\n",
       "Age                     float64\n",
       "Education               float64\n",
       "Income                  float64\n",
       "Diabetes_binary           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns with NA values\n",
    "print(data.isna().sum())\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which columns we see correlations with Diabetes_binary before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary         1.000000\n",
      "GenHlth                 0.300785\n",
      "HighBP                  0.270334\n",
      "BMI                     0.223851\n",
      "DiffWalk                0.222155\n",
      "HighChol                0.210290\n",
      "Age                     0.185891\n",
      "HeartDiseaseorAttack    0.176933\n",
      "PhysHlth                0.174948\n",
      "Stroke                  0.104800\n",
      "MentHlth                0.074971\n",
      "CholCheck               0.067879\n",
      "Smoker                  0.062778\n",
      "NoDocbcCost             0.038025\n",
      "Sex                     0.029606\n",
      "AnyHealthcare           0.014079\n",
      "Fruits                 -0.042088\n",
      "HvyAlcoholConsump      -0.056682\n",
      "Veggies                -0.059219\n",
      "PhysActivity           -0.121392\n",
      "Education              -0.131803\n",
      "Income                 -0.172794\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = data.corrwith(data['Diabetes_binary'])\n",
    "print(correlations.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of diabetes/prediabetes or Neither (0,1) in data set: 0.15758830022075054\n"
     ]
    }
   ],
   "source": [
    "# Determine the composition of our Diabetes Binary Class for our modeling \n",
    "print(\"Ratio of diabetes/prediabetes or Neither (0,1) in data set:\", data['Diabetes_binary'].sum() / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep for modeling\n",
    "\n",
    "This dataset contains class imbalance with only ~15.7% of the data having diabetes. With our predictions we need to sample the data in a way for training that will allow the diabetes data to be trained properly. We will be using the imbalanaced-learn package to sample the data with the SMOTE (Synthetic Minority Over-sampling Technique). Using only the training data with SMOTE will avoid data leakage into the testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12\n",
    "\n",
    "# Model variables\n",
    "X = data.drop([\"Diabetes_binary\"], axis = 1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=random_state)\n",
    "\n",
    "# Use SMOTE for balancing the training data\n",
    "smote = SMOTE(random_state=random_state)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "## Overview\n",
    "Our goal is to pinpoint the best-performing classification model for our dataset. By employing SMOTE for dataset balancing, optimizing hyperparameters with Grid Search CV, and utilizing all CPU cores for efficient processing, we navigate towards an informed model selection.\n",
    "\n",
    "## Models and Their Strengths\n",
    "- **Logistic Regression**: A fundamental model for binary outcomes, valued for its simplicity and interpretability. It estimates probabilities that allow for a clear threshold decision.\n",
    "\n",
    "- **Random Forest Classifier**: Utilizes an ensemble of decision trees to reduce overfitting and improve prediction accuracy. It's known for its robustness and ability to handle non-linear data.\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**: A non-parametric method that classifies each data point based on the majority label of its nearest neighbors. It's simple yet effective, with performance depending on the choice of the distance metric and the value of k.\n",
    "\n",
    "- **Gradient Boosting Classifier**: Builds models sequentially, each correcting its predecessor, which combines weak models to create a strong model. It's powerful for handling various data types and relationships.\n",
    "\n",
    "- **LinearSVC (Support Vector Machine)**: A variant of SVM optimized for linear classification. It's effective in high-dimensional spaces and for cases where the number of dimensions exceeds the number of samples.\n",
    "\n",
    "## Evaluation Strategy\n",
    "Our comprehensive assessment leans on accuracy, Precision, Recall, F1 Score, and ROC AUC to offer a holistic view of model performance. These metrics are crucial for understanding how well each model can manage class imbalances and make accurate classifications.\n",
    "\n",
    "## Outcome\n",
    "This methodical approach will lead us to select a model that not only performs well across our metrics but also effectively handles the nuances of our specific dataset, ensuring reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
      "Best ROC AUC for Logistic Regression: 0.8220\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82     42646\n",
      "           1       0.34      0.77      0.47      8090\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.65     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.8194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=random_state, max_iter=1000), param_grid_lr, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_lr.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best ROC AUC for Logistic Regression: {grid_search_lr.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_lr = grid_search_lr.predict(X_test)\n",
    "y_pred_proba_lr = grid_search_lr.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_lr:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'n_estimators': 100}\n",
      "Best ROC AUC for Random Forest: 0.9700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     42646\n",
      "           1       0.46      0.33      0.38      8090\n",
      "\n",
      "    accuracy                           0.83     50736\n",
      "   macro avg       0.67      0.63      0.64     50736\n",
      "weighted avg       0.81      0.83      0.82     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.7947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],  \n",
    "    'max_depth': [None, 10, 20, 30]  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=random_state), param_grid_rf, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best ROC AUC for Random Forest: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_pred_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_rf:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "Best ROC AUC for KNN: 0.9074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84     42646\n",
      "           1       0.31      0.50      0.38      8090\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.60      0.65      0.61     50736\n",
      "weighted avg       0.80      0.75      0.77     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9], \n",
    "    'metric': ['euclidean', 'manhattan']  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_knn.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for KNN: {grid_search_knn.best_params_}\")\n",
    "print(f\"Best ROC AUC for KNN: {grid_search_knn.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_knn = grid_search_knn.predict(X_test)\n",
    "\n",
    "# Since KNN doesn't directly support predict_proba, we use a workaround or skip ROC AUC\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best ROC AUC for Gradient Boosting: 0.9577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     42646\n",
      "           1       0.50      0.36      0.42      8090\n",
      "\n",
      "    accuracy                           0.84     50736\n",
      "   macro avg       0.70      0.65      0.67     50736\n",
      "weighted avg       0.82      0.84      0.83     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.8214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 7]  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=random_state), param_grid_gb, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_gb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Gradient Boosting: {grid_search_gb.best_params_}\")\n",
    "print(f\"Best ROC AUC for Gradient Boosting: {grid_search_gb.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_gb = grid_search_gb.predict(X_test)\n",
    "y_pred_proba_gb = grid_search_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_gb = roc_auc_score(y_test, y_pred_proba_gb)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_gb:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC (with Calibration):\n",
      "Accuracy: 0.7279, Precision: 0.3424, Recall: 0.7674, F1 Score: 0.4735, ROC AUC: 0.8194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82     42646\n",
      "           1       0.34      0.77      0.47      8090\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.65     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Initialize LinearSVC\n",
    "linear_svc = LinearSVC(random_state=random_state, max_iter=1000, dual='auto')\n",
    "\n",
    "# Calibrate model to allow for probability estimates\n",
    "calibrated_svc = CalibratedClassifierCV(linear_svc, method='sigmoid', cv=3)\n",
    "calibrated_svc.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svc = calibrated_svc.predict(X_test)\n",
    "\n",
    "# Obtain probabilities for ROC AUC\n",
    "y_pred_proba_svc = calibrated_svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "roc_auc_svc = roc_auc_score(y_test, y_pred_proba_svc)\n",
    "\n",
    "# Print metrics\n",
    "print(\"LinearSVC (with Calibration):\")\n",
    "print(f\"Accuracy: {accuracy_svc:.4f}, Precision: {precision_svc:.4f}, Recall: {recall_svc:.4f}, F1 Score: {f1_svc:.4f}, ROC AUC: {roc_auc_svc:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
