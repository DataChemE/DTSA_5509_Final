{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Classification Dataset\n",
    "\n",
    "This project focuses on utilizing data from the Behavioral Risk Factor Surveillance System (BRFSS), an annual health-related telephone survey conducted by the CDC. Our primary goal is to leverage machine learning models for the classification of diabetes risk among patients, enabling comparisons of model performances based on various model types and dataset characteristics. Effective classification can significantly contribute to early detection of diabetes or prediabetes, thus preventing severe health outcomes associated with these conditions. Early identification fosters improved patient care and aids physicians in making informed diagnostic decisions.\n",
    "\n",
    "The dataset for this study, `diabetes_012_health_indicators_BRFSS2015.csv`, comprises 253,680 responses from the BRFSS 2015 survey. It features a target variable, `Diabetes_012`, categorized into three classes: '0' for no diabetes or cases only during pregnancy, '1' for prediabetes, and '2' for diabetes, highlighting a prevalent class imbalance. This dataset, enriched with 21 feature variables, serves as a critical tool for our analysis.\n",
    "\n",
    "Our data is sourced from the University of California Irvine Machine Learning Repository and is available on Kaggle, initially derived from the CDC's dataset. These sources ensure a comprehensive foundation for our machine learning endeavors aimed at diabetes classification.\n",
    "\n",
    "**Citations:**\n",
    "- [CDC (2015). Behavioral Risk Factor Surveillance System. Retrieved from Kaggle Dataset.](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset)\n",
    "\n",
    "- UCI Machine Learning Repository. Diabetes Health Indicators Dataset. Available at: https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports, package imports and dataframe setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries for the project\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a DataFrame in pandas\n",
    "data = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset:(253680, 22)\n",
      "Total Memory Usage: 42.58 MB\n",
      "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
      "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(f\"Shape of dataset:{data.shape}\")\n",
    "\n",
    "# MegaByte size of the file\n",
    "total_memory_usage_bytes = data.memory_usage(deep=True).sum()\n",
    "megabytes = total_memory_usage_bytes / (1024**2)\n",
    "print(f'Total Memory Usage: {megabytes:.2f} MB')\n",
    "\n",
    "# All column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012            float64\n",
      "HighBP                  float64\n",
      "HighChol                float64\n",
      "CholCheck               float64\n",
      "BMI                     float64\n",
      "Smoker                  float64\n",
      "Stroke                  float64\n",
      "HeartDiseaseorAttack    float64\n",
      "PhysActivity            float64\n",
      "Fruits                  float64\n",
      "Veggies                 float64\n",
      "HvyAlcoholConsump       float64\n",
      "AnyHealthcare           float64\n",
      "NoDocbcCost             float64\n",
      "GenHlth                 float64\n",
      "MentHlth                float64\n",
      "PhysHlth                float64\n",
      "DiffWalk                float64\n",
      "Sex                     float64\n",
      "Age                     float64\n",
      "Education               float64\n",
      "Income                  float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types for all columns \n",
    "print(data.dtypes)\n",
    "\n",
    "# Print out the first five rows \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description for Diabetes Classification Dataset\n",
    "\n",
    "The dataset consists of responses from the Behavioral Risk Factor Surveillance System (BRFSS) 2015 survey, aimed at classifying the risk of diabetes among individuals. It encompasses a total of **253,680 samples (rows)** and **22 features (columns)**, with a total memory usage of **42.58 MB**. This sizeable dataset provides a robust foundation for developing and evaluating machine learning models.\n",
    "\n",
    "#### Feature Overview:\n",
    "- **Target Variable**: `Diabetes_012` categorizes individuals into three groups: 0 for no diabetes or only during pregnancy, 1 for prediabetes, and 2 for diabetes. This variable is crucial for our classification task.\n",
    "- **Binary Features**: Several features are binary (0 or 1), indicating the presence or absence of certain health conditions or behaviors, including `HighBP` (high blood pressure), `HighChol` (high cholesterol), `Smoker`, `Stroke`, `HeartDiseaseorAttack`, `PhysActivity`, `Fruits`, `Veggies`, `HvyAlcoholConsump`, `AnyHealthcare`, `NoDocbcCost`, and `DiffWalk`.\n",
    "- **Continuous Features**: `BMI` represents the Body Mass Index, a key indicator of health. `GenHlth` (general health status), `MentHlth` (days of poor mental health), and `PhysHlth` (days of poor physical health) are ordinal features reflecting health conditions.\n",
    "- **Demographic Features**: `Sex`, `Age`, `Education`, and `Income` provide demographic context, essential for understanding health patterns across different populations.\n",
    "\n",
    "#### Data Characteristics:\n",
    "- The dataset is primarily tabular, with a mix of binary, continuous, and ordinal data types. This diversity requires careful preprocessing to ensure models can effectively learn from the data.\n",
    "- Features like `Age`, `Education`, and `Income` are ordinal, presenting a range of values that need to be appropriately handled during the modeling process.\n",
    "- The class imbalance in the target variable (`Diabetes_012`) poses a significant challenge, necessitating strategies like SMOTE for balancing during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012              int64\n",
      "HighBP                    int64\n",
      "HighChol                  int64\n",
      "CholCheck                 int64\n",
      "BMI                     float64\n",
      "Smoker                    int64\n",
      "Stroke                    int64\n",
      "HeartDiseaseorAttack      int64\n",
      "PhysActivity              int64\n",
      "Fruits                    int64\n",
      "Veggies                   int64\n",
      "HvyAlcoholConsump         int64\n",
      "AnyHealthcare             int64\n",
      "NoDocbcCost               int64\n",
      "GenHlth                 float64\n",
      "MentHlth                float64\n",
      "PhysHlth                float64\n",
      "DiffWalk                  int64\n",
      "Sex                       int64\n",
      "Age                     float64\n",
      "Education               float64\n",
      "Income                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the binary columns from float type to int to help with memory/speed when training the data\n",
    "non_binary_columns = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "\n",
    "# Loop through all columns in the dataframe\n",
    "for column in data.columns:\n",
    "    # If the column is not in the list of non-binary columns, convert it to int\n",
    "    if column not in non_binary_columns:\n",
    "        data[column] = data[column].astype(int)\n",
    "\n",
    "\n",
    "# Print out all dtypes after conversion to int\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale our non-binary data to help with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinMaxScaler for scaling data \n",
    "scaler = MinMaxScaler()\n",
    "data[non_binary_columns] = scaler.fit_transform(data[non_binary_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Diabetes Column as Binary value\n",
    "The original data has it as 0 for no diabetes or only during pregnancy, 1 is for prediabetes, and 2 is for diabetes. We will encode the data as either 0 for no diabetes or only during pregnancy, and 1 for prediabetes/diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset to Encode the diabetes column as binary for 0 = no diabetes, and 1 == pre-diabetes or diabetes\n",
    "data['Diabetes_binary'] = (data['Diabetes_012'] > 0).astype(int)\n",
    "\n",
    "# Drop the orginal 'Diabetes_012' column to avoid multicollinearity\n",
    "data = data.drop('Diabetes_012', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighBP                  0\n",
      "HighChol                0\n",
      "CholCheck               0\n",
      "BMI                     0\n",
      "Smoker                  0\n",
      "Stroke                  0\n",
      "HeartDiseaseorAttack    0\n",
      "PhysActivity            0\n",
      "Fruits                  0\n",
      "Veggies                 0\n",
      "HvyAlcoholConsump       0\n",
      "AnyHealthcare           0\n",
      "NoDocbcCost             0\n",
      "GenHlth                 0\n",
      "MentHlth                0\n",
      "PhysHlth                0\n",
      "DiffWalk                0\n",
      "Sex                     0\n",
      "Age                     0\n",
      "Education               0\n",
      "Income                  0\n",
      "Diabetes_binary         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HighBP                    int64\n",
       "HighChol                  int64\n",
       "CholCheck                 int64\n",
       "BMI                     float64\n",
       "Smoker                    int64\n",
       "Stroke                    int64\n",
       "HeartDiseaseorAttack      int64\n",
       "PhysActivity              int64\n",
       "Fruits                    int64\n",
       "Veggies                   int64\n",
       "HvyAlcoholConsump         int64\n",
       "AnyHealthcare             int64\n",
       "NoDocbcCost               int64\n",
       "GenHlth                 float64\n",
       "MentHlth                float64\n",
       "PhysHlth                float64\n",
       "DiffWalk                  int64\n",
       "Sex                       int64\n",
       "Age                     float64\n",
       "Education               float64\n",
       "Income                  float64\n",
       "Diabetes_binary           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns with NA values\n",
    "print(data.isna().sum())\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which columns we see correlations with Diabetes_binary before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary         1.000000\n",
      "GenHlth                 0.300785\n",
      "HighBP                  0.270334\n",
      "BMI                     0.223851\n",
      "DiffWalk                0.222155\n",
      "HighChol                0.210290\n",
      "Age                     0.185891\n",
      "HeartDiseaseorAttack    0.176933\n",
      "PhysHlth                0.174948\n",
      "Stroke                  0.104800\n",
      "MentHlth                0.074971\n",
      "CholCheck               0.067879\n",
      "Smoker                  0.062778\n",
      "NoDocbcCost             0.038025\n",
      "Sex                     0.029606\n",
      "AnyHealthcare           0.014079\n",
      "Fruits                 -0.042088\n",
      "HvyAlcoholConsump      -0.056682\n",
      "Veggies                -0.059219\n",
      "PhysActivity           -0.121392\n",
      "Education              -0.131803\n",
      "Income                 -0.172794\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = data.corrwith(data['Diabetes_binary'])\n",
    "print(correlations.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of diabetes/prediabetes or Neither (0,1) in data set: 0.15758830022075054\n"
     ]
    }
   ],
   "source": [
    "# Determine the composition of our Diabetes Binary Class for our modeling \n",
    "print(\"Ratio of diabetes/prediabetes or Neither (0,1) in data set:\", data['Diabetes_binary'].sum() / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data balancing for modeling\n",
    "\n",
    "This dataset contains class imbalance with only ~15.7% of the data having diabetes. With our predictions we need to sample the data in a way for training that will allow the diabetes data to be trained properly. We will be using the imbalanaced-learn package to sample the data with the SMOTE (Synthetic Minority Over-sampling Technique). Using only the training data with SMOTE will avoid data leakage into the testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12\n",
    "\n",
    "# Model variables\n",
    "X = data.drop([\"Diabetes_binary\"], axis = 1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=random_state)\n",
    "\n",
    "# Use SMOTE for balancing the training data\n",
    "smote = SMOTE(random_state=random_state)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Summary\n",
    "\n",
    "The preliminary stage of our analysis involved a meticulous data cleaning process, crucial for preparing the dataset for effective model training and ensuring reliable predictions. This section outlines our cleaning methodology, the rationale behind each step, and the implications of these actions on our dataset.\n",
    "\n",
    "### Conversion of Binary Columns\n",
    "\n",
    "Our initial step focused on optimizing the dataset for memory efficiency and computational speed. We identified several columns representing binary variables (e.g., `HighBP`, `Smoker`, `PhysActivity`) that were incorrectly typed as `float64`. To address this:\n",
    "\n",
    "- **Action**: Converted all binary variables, except for the explicitly listed non-binary columns, from `float64` to `int64`.\n",
    "- **Rationale**: This type conversion reduces memory usage and aligns with the binary nature of these variables, enhancing model performance.\n",
    "- **Impact**: Post-conversion, the dataset's memory footprint decreased, facilitating faster computations during model training.\n",
    "\n",
    "### Scaling Non-Binary Data\n",
    "\n",
    "Given the presence of continuous and ordinal variables within our dataset, scaling was imperative to normalize the data distribution:\n",
    "\n",
    "- **Action**: Applied `MinMaxScaler` to non-binary columns (`BMI`, `GenHlth`, `MentHlth`, `PhysHlth`, `Age`, `Education`, `Income`).\n",
    "- **Rationale**: Scaling ensures that these variables contribute equally to model training, preventing features with larger ranges from disproportionately influencing the model.\n",
    "- **Impact**: This step prepared our dataset for algorithms sensitive to the scale of input features, promoting a balanced learning environment.\n",
    "\n",
    "### Encoding the Target Variable\n",
    "\n",
    "With the goal of simplifying our classification task, we modified the target variable to reflect a binary outcome:\n",
    "\n",
    "- **Action**: Encoded `Diabetes_012` into a binary variable, `Diabetes_binary`, distinguishing between no diabetes (0) and the presence of prediabetes/diabetes (1).\n",
    "- **Rationale**: This encoding addresses the class imbalance and refines our classification objective to a binary task, streamlining model interpretation.\n",
    "- **Impact**: The redefined target variable facilitates a focused analysis on the binary classification of diabetes risk, enhancing model clarity and relevance.\n",
    "\n",
    "### Addressing Missing Values and Final Preparations\n",
    "\n",
    "A thorough examination for missing values was conducted to ensure dataset completeness:\n",
    "\n",
    "- **Action**: Checked for and addressed NA values across the dataset. Our dataset revealed no missing values, obviating the need for imputation.\n",
    "- **Rationale**: Missing data can introduce bias and affect model accuracy. Confirming the absence of NAs ensures the integrity of our analysis.\n",
    "- **Impact**: With a complete dataset, we proceed with confidence that our models will learn from a comprehensive representation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "## Overview\n",
    "Our goal is to pinpoint the best-performing classification model for our dataset. By employing SMOTE for dataset balancing, optimizing hyperparameters with Grid Search CV, and utilizing all CPU cores for efficient processing, we navigate towards an informed model selection.\n",
    "\n",
    "## Models and Their Strengths\n",
    "- **Logistic Regression**: A fundamental model for binary outcomes, valued for its simplicity and interpretability. It estimates probabilities that allow for a clear threshold decision.\n",
    "\n",
    "- **Random Forest Classifier**: Utilizes an ensemble of decision trees to reduce overfitting and improve prediction accuracy. It's known for its robustness and ability to handle non-linear data.\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**: A non-parametric method that classifies each data point based on the majority label of its nearest neighbors. It's simple yet effective, with performance depending on the choice of the distance metric and the value of k.\n",
    "\n",
    "- **Gradient Boosting Classifier**: Builds models sequentially, each correcting its predecessor, which combines weak models to create a strong model. It's powerful for handling various data types and relationships.\n",
    "\n",
    "- **LinearSVC (Support Vector Machine)**: A variant of SVM optimized for linear classification. It's effective in high-dimensional spaces and for cases where the number of dimensions exceeds the number of samples.\n",
    "\n",
    "## Evaluation Strategy\n",
    "Our comprehensive assessment leans on accuracy, Precision, Recall, F1 Score, and ROC AUC to offer a holistic view of model performance. These metrics are crucial for understanding how well each model can manage class imbalances and make accurate classifications.\n",
    "\n",
    "## Outcome\n",
    "This methodical approach will lead us to select a model that not only performs well across our metrics but also effectively handles the nuances of our specific dataset, ensuring reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
      "Best ROC AUC for Logistic Regression: 0.8220\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82     42646\n",
      "           1       0.34      0.77      0.47      8090\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.65     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.8194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=random_state, max_iter=1000), param_grid_lr, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_lr.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best ROC AUC for Logistic Regression: {grid_search_lr.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_lr = grid_search_lr.predict(X_test)\n",
    "y_pred_proba_lr = grid_search_lr.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_lr:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'n_estimators': 100}\n",
      "Best ROC AUC for Random Forest: 0.9700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     42646\n",
      "           1       0.46      0.33      0.38      8090\n",
      "\n",
      "    accuracy                           0.83     50736\n",
      "   macro avg       0.67      0.63      0.64     50736\n",
      "weighted avg       0.81      0.83      0.82     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.7947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],  \n",
    "    'max_depth': [None, 10, 20, 30]  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=random_state), param_grid_rf, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best ROC AUC for Random Forest: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_pred_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_rf:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "Best ROC AUC for KNN: 0.9074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84     42646\n",
      "           1       0.31      0.50      0.38      8090\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.60      0.65      0.61     50736\n",
      "weighted avg       0.80      0.75      0.77     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9], \n",
    "    'metric': ['euclidean', 'manhattan']  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_knn.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for KNN: {grid_search_knn.best_params_}\")\n",
    "print(f\"Best ROC AUC for KNN: {grid_search_knn.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_knn = grid_search_knn.predict(X_test)\n",
    "\n",
    "# Since KNN doesn't directly support predict_proba, we use a workaround or skip ROC AUC\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best ROC AUC for Gradient Boosting: 0.9577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     42646\n",
      "           1       0.50      0.36      0.42      8090\n",
      "\n",
      "    accuracy                           0.84     50736\n",
      "   macro avg       0.70      0.65      0.67     50736\n",
      "weighted avg       0.82      0.84      0.83     50736\n",
      "\n",
      "ROC AUC on Test Set: 0.8214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 7]  \n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=random_state), param_grid_gb, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_gb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best parameters for Gradient Boosting: {grid_search_gb.best_params_}\")\n",
    "print(f\"Best ROC AUC for Gradient Boosting: {grid_search_gb.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_gb = grid_search_gb.predict(X_test)\n",
    "y_pred_proba_gb = grid_search_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Calculate and print ROC AUC\n",
    "roc_auc_gb = roc_auc_score(y_test, y_pred_proba_gb)\n",
    "print(f\"ROC AUC on Test Set: {roc_auc_gb:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC (with Calibration):\n",
      "Accuracy: 0.7279, Precision: 0.3424, Recall: 0.7674, F1 Score: 0.4735, ROC AUC: 0.8194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82     42646\n",
      "           1       0.34      0.77      0.47      8090\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.65     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Initialize LinearSVC\n",
    "linear_svc = LinearSVC(random_state=random_state, max_iter=1000, dual='auto')\n",
    "\n",
    "# Calibrate model to allow for probability estimates\n",
    "calibrated_svc = CalibratedClassifierCV(linear_svc, method='sigmoid', cv=3)\n",
    "calibrated_svc.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svc = calibrated_svc.predict(X_test)\n",
    "\n",
    "# Obtain probabilities for ROC AUC\n",
    "y_pred_proba_svc = calibrated_svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "roc_auc_svc = roc_auc_score(y_test, y_pred_proba_svc)\n",
    "\n",
    "# Print metrics\n",
    "print(\"LinearSVC (with Calibration):\")\n",
    "print(f\"Accuracy: {accuracy_svc:.4f}, Precision: {precision_svc:.4f}, Recall: {recall_svc:.4f}, F1 Score: {f1_svc:.4f}, ROC AUC: {roc_auc_svc:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
